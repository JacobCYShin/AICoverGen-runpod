""" AICoverGen Handler for RunPod Serverless """

import os
import json
import base64
import tempfile
import logging
import shutil
from typing import Dict, Any, Optional
import traceback

import runpod
import torch
import numpy as np
import gc
import hashlib
import requests
import time
import boto3
from botocore.exceptions import ClientError, NoCredentialsError

# AICoverGen imports
import sys

# Add src directory to Python path
current_dir = os.path.dirname(os.path.abspath(__file__))
src_path = os.path.join(current_dir, 'src')
sys.path.insert(0, src_path)

try:
    from rvc import Config, load_hubert, get_vc, rvc_infer
    from webui import get_current_models, rvc_models_dir, mdxnet_models_dir, output_dir
except ImportError as e:
    print(f"AICoverGen ëª¨ë“ˆ import ì‹¤íŒ¨: {e}")
    raise

# Import main module to override its paths at runtime
import main as main_module

# Override paths for RunPod Serverless
RUNPOD_RVC_MODELS_DIR = "/runpod-volume/rvc_models"
RUNPOD_MDXNET_MODELS_DIR = "/runpod-volume/mdxnet_models"
RUNPOD_OUTPUT_DIR = "/runpod-volume/output"

# Audio processing imports
try:
    from pedalboard import Pedalboard, Reverb, Compressor, HighpassFilter
    from pedalboard.io import AudioFile
    from pydub import AudioSegment
    import soundfile as sf
    import sox
except ImportError as e:
    print(f"Audio processing ëª¨ë“ˆ import ì‹¤íŒ¨: {e}")
    raise

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# AWS S3 ì„¤ì • (í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°)
AWS_ACCESS_KEY_ID = os.getenv('AWS_ACCESS_KEY_ID')
AWS_SECRET_ACCESS_KEY = os.getenv('AWS_SECRET_ACCESS_KEY')
AWS_REGION = os.getenv('AWS_REGION', 'us-east-1')
S3_BUCKET_NAME = os.getenv('S3_BUCKET_NAME', 'likebutter-bucket')

# S3 ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ ì²´í¬
S3_AVAILABLE = bool(AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY and S3_BUCKET_NAME)

# S3 í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
def get_s3_client():
    """S3 í´ë¼ì´ì–¸íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        if not AWS_ACCESS_KEY_ID or not AWS_SECRET_ACCESS_KEY:
            logger.warning("AWS ì¸ì¦ ì •ë³´ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return None
            
        return boto3.client(
            's3',
            aws_access_key_id=AWS_ACCESS_KEY_ID,
            aws_secret_access_key=AWS_SECRET_ACCESS_KEY,
            region_name=AWS_REGION
        )
    except Exception as e:
        logger.error(f"S3 í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return None

# RunPod ì—…ë¡œë“œ ìœ í‹¸ë¦¬í‹° (URL ë°˜í™˜ìš©)
try:
    from runpod.serverless.utils import rp_upload
except Exception:  # ë¡œì»¬ í™˜ê²½ ëŒ€ë¹„
    rp_upload = None

# Ensure directories exist
os.makedirs(RUNPOD_RVC_MODELS_DIR, exist_ok=True)
os.makedirs(RUNPOD_MDXNET_MODELS_DIR, exist_ok=True)
os.makedirs(RUNPOD_OUTPUT_DIR, exist_ok=True)

# Check if base models exist in volume
def check_base_models_in_volume():
    """ë³¼ë¥¨ì— ê¸°ë³¸ ëª¨ë¸ íŒŒì¼ë“¤ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸"""
    try:
        required_models = ["hubert_base.pt", "rmvpe.pt"]
        missing_models = []
        
        for fname in required_models:
            model_path = os.path.join(RUNPOD_RVC_MODELS_DIR, fname)
            if os.path.exists(model_path):
                file_size = os.path.getsize(model_path) / (1024 * 1024)  # MB
                logger.info(f"ê¸°ë³¸ ëª¨ë¸ í™•ì¸: {fname} ({file_size:.1f}MB)")
                
                # íŒŒì¼ í¬ê¸° ê²€ì¦
                if fname == "hubert_base.pt" and file_size < 80:
                    logger.warning(f"hubert_base.pt íŒŒì¼ì´ ë„ˆë¬´ ì‘ìŒ ({file_size:.1f}MB)")
                    missing_models.append(fname)
                elif fname == "rmvpe.pt" and file_size < 10:
                    logger.warning(f"rmvpe.pt íŒŒì¼ì´ ë„ˆë¬´ ì‘ìŒ ({file_size:.1f}MB)")
                    missing_models.append(fname)
            else:
                logger.warning(f"ê¸°ë³¸ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŒ: {model_path}")
                missing_models.append(fname)
        
        if missing_models:
            logger.warning(f"ëˆ„ë½ëœ ê¸°ë³¸ ëª¨ë¸: {missing_models}")
            return False
        else:
            logger.info("ëª¨ë“  ê¸°ë³¸ ëª¨ë¸ì´ ì •ìƒì ìœ¼ë¡œ ì¡´ì¬í•¨")
            return True
            
    except Exception as e:
        logger.warning(f"ê¸°ë³¸ ëª¨ë¸ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
        return False

check_base_models_in_volume()

# S3 ì„¤ì • ìƒíƒœ ë¡œê¹… (ìƒì„¸ ë””ë²„ê¹…)
logger.info("ğŸ” í™˜ê²½ë³€ìˆ˜ ë””ë²„ê¹…:")
logger.info(f"  AWS_ACCESS_KEY_ID: {'ì„¤ì •ë¨' if AWS_ACCESS_KEY_ID else 'ì—†ìŒ'} (ê¸¸ì´: {len(AWS_ACCESS_KEY_ID) if AWS_ACCESS_KEY_ID else 0})")
logger.info(f"  AWS_SECRET_ACCESS_KEY: {'ì„¤ì •ë¨' if AWS_SECRET_ACCESS_KEY else 'ì—†ìŒ'} (ê¸¸ì´: {len(AWS_SECRET_ACCESS_KEY) if AWS_SECRET_ACCESS_KEY else 0})")
logger.info(f"  AWS_REGION: {AWS_REGION}")
logger.info(f"  S3_BUCKET_NAME: {S3_BUCKET_NAME}")

if S3_AVAILABLE:
    logger.info(f"âœ… S3 ì—°ê²° ê°€ëŠ¥: ë²„í‚·={S3_BUCKET_NAME}, ë¦¬ì „={AWS_REGION}")
else:
    logger.warning("âš ï¸ S3 ì—°ê²° ë¶ˆê°€: AWS ìê²©ì¦ëª… ë˜ëŠ” ë²„í‚·ëª…ì´ ì„¤ì •ë˜ì§€ ì•ŠìŒ. base64 ë°©ì‹ë§Œ ì‚¬ìš© ê°€ëŠ¥.")
    
    # ëª¨ë“  í™˜ê²½ë³€ìˆ˜ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
    logger.warning("ì „ì²´ í™˜ê²½ë³€ìˆ˜ ëª©ë¡:")
    for key, value in os.environ.items():
        if 'AWS' in key or 'S3' in key:
            logger.warning(f"  {key}: {'ì„¤ì •ë¨' if value else 'ì—†ìŒ'}")

def _download_from_s3(s3_url: str) -> str:
    """S3 URLì—ì„œ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ì„ì‹œ íŒŒì¼ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        logger.info(f"S3 URL ë‹¤ìš´ë¡œë“œ ì‹œì‘: {s3_url}")
        
        # S3 URL íŒŒì‹± - ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›
        # í˜•ì‹ 1: https://bucket.s3.region.amazonaws.com/key
        # í˜•ì‹ 2: https://s3.region.amazonaws.com/bucket/key  
        # í˜•ì‹ 3: https://bucket.s3.amazonaws.com/key (us-east-1)
        
        if not s3_url.startswith('https://'):
            raise ValueError(f"Invalid S3 URL format: {s3_url}")
            
        url_without_protocol = s3_url.replace('https://', '')
        url_parts = url_without_protocol.split('/')
        
        if len(url_parts) < 2:
            raise ValueError(f"Invalid S3 URL format: {s3_url}")
        
        # ë„ë©”ì¸ ë¶€ë¶„ê³¼ ê²½ë¡œ ë¶€ë¶„ ë¶„ë¦¬
        domain_part = url_parts[0]
        path_parts = url_parts[1:]
        
        if 's3' in domain_part:
            if domain_part.startswith('s3.'):
                # í˜•ì‹ 2: s3.region.amazonaws.com/bucket/key
                bucket_name = path_parts[0]
                s3_key = '/'.join(path_parts[1:])
            else:
                # í˜•ì‹ 1, 3: bucket.s3.region.amazonaws.com/key
                bucket_name = domain_part.split('.')[0]
                s3_key = '/'.join(path_parts)
        else:
            raise ValueError(f"Not a valid S3 URL: {s3_url}")
            
        if not bucket_name or not s3_key:
            raise ValueError(f"Could not parse bucket or key from URL: {s3_url}")
        
        logger.info(f"íŒŒì‹±ëœ S3 ì •ë³´: bucket={bucket_name}, key={s3_key}")
        
        # S3 í´ë¼ì´ì–¸íŠ¸ ê°€ì ¸ì˜¤ê¸°
        s3_client = get_s3_client()
        if s3_client is None:
            raise RuntimeError("S3 í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. AWS ìê²©ì¦ëª…ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        
        # ì„ì‹œ íŒŒì¼ ìƒì„± - í™•ì¥ì ì¶”ì¶œ ì‹œë„
        file_extension = '.wav'  # ê¸°ë³¸ê°’
        if '.' in s3_key:
            file_extension = '.' + s3_key.split('.')[-1]
            
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=file_extension)
        temp_file_path = temp_file.name
        temp_file.close()
        
        # S3ì—ì„œ ë‹¤ìš´ë¡œë“œ
        logger.info(f"S3 ë‹¤ìš´ë¡œë“œ ì‹œì‘: {bucket_name}/{s3_key} -> {temp_file_path}")
        s3_client.download_file(bucket_name, s3_key, temp_file_path)
        
        # ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ í¬ê¸° í™•ì¸
        file_size = os.path.getsize(temp_file_path)
        logger.info(f"S3 ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {temp_file_path} ({file_size} bytes)")
        
        return temp_file_path
        
    except Exception as e:
        logger.error(f"S3 ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {s3_url} - {e}")
        # ìƒì„¸í•œ ì—ëŸ¬ ì •ë³´ ë¡œê¹…
        logger.error(f"ì—ëŸ¬ íƒ€ì…: {type(e).__name__}")
        if hasattr(e, 'response'):
            logger.error(f"AWS ì‘ë‹µ: {e.response}")
        raise

def _upload_to_s3(file_path: str, file_type: str = "audio") -> str:
    """íŒŒì¼ì„ S3ì— ì—…ë¡œë“œí•˜ê³  ê³µê°œ URLì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"ì—…ë¡œë“œí•  íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")
            
        s3_client = get_s3_client()
        if s3_client is None:
            raise RuntimeError("S3 í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. AWS ìê²©ì¦ëª…ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        
        # íŒŒì¼ í¬ê¸° í™•ì¸
        file_size = os.path.getsize(file_path)
        logger.info(f"S3 ì—…ë¡œë“œ ì‹œì‘: {file_path} ({file_size} bytes)")
        
        # S3 í‚¤ ìƒì„± (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨)
        timestamp = int(time.time())
        file_name = os.path.basename(file_path)
        
        if file_type == "audio":
            s3_key = f"generated-audios/{timestamp}_{file_name}"
        else:
            s3_key = f"generated-images/{timestamp}_{file_name}"
        
        # S3ì— ì—…ë¡œë“œ
        logger.info(f"S3 ì—…ë¡œë“œ ì¤‘: {S3_BUCKET_NAME}/{s3_key}")
        s3_client.upload_file(file_path, S3_BUCKET_NAME, s3_key)
        
        # S3 ê³µê°œ URL ìƒì„±
        s3_url = f"https://{S3_BUCKET_NAME}.s3.{AWS_REGION}.amazonaws.com/{s3_key}"
        
        logger.info(f"S3 ì—…ë¡œë“œ ì™„ë£Œ: {file_path} -> {s3_url}")
        return s3_url
        
    except Exception as e:
        logger.error(f"S3 ì—…ë¡œë“œ ì‹¤íŒ¨: {file_path} - {e}")
        # ìƒì„¸í•œ ì—ëŸ¬ ì •ë³´ ë¡œê¹…
        logger.error(f"ì—ëŸ¬ íƒ€ì…: {type(e).__name__}")
        if hasattr(e, 'response'):
            logger.error(f"AWS ì‘ë‹µ: {e.response}")
        raise

def _encode_outputs_as_base64(file_paths: list[str]) -> Dict[str, str]:
    """ì¶œë ¥ íŒŒì¼ì„ base64ë¡œ ì¸ì½”ë”©í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
    result_files: Dict[str, str] = {}
    for output_file in file_paths:
        if os.path.exists(output_file):
            try:
                with open(output_file, "rb") as f:
                    file_data = f.read()
                    file_name = os.path.basename(output_file)
                    
                    # íŒŒì¼ í¬ê¸° í™•ì¸ ë° ì••ì¶• ê³ ë ¤
                    file_size = len(file_data)
                    logger.info(f"íŒŒì¼ í¬ê¸°: {file_name} = {file_size} bytes ({file_size / 1024 / 1024:.2f} MB)")
                    
                    # íŒŒì¼ì´ ë„ˆë¬´ í¬ë©´ ê²½ê³ 
                    if file_size > 50 * 1024 * 1024:  # 50MB
                        logger.warning(f"íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤: {file_name} ({file_size / 1024 / 1024:.2f} MB)")
                        # íŒŒì¼ì„ ê±´ë„ˆë›°ê³  ê²½ê³ ë§Œ ë°˜í™˜
                        result_files[f"{file_name}_SKIPPED"] = "File too large"
                        continue
                    
                    result_files[file_name] = base64.b64encode(file_data).decode('utf-8')
                    logger.info(f"íŒŒì¼ ì¸ì½”ë”© ì™„ë£Œ: {file_name}")
            except Exception as e:
                logger.error(f"íŒŒì¼ ì¸ì½”ë”© ì‹¤íŒ¨: {output_file} - {e}")
                result_files[f"{os.path.basename(output_file)}_ERROR"] = str(e)
        else:
            logger.warning(f"íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {output_file}")
    return result_files

def _upload_outputs_and_get_urls(file_paths: list[str]) -> Dict[str, str]:
    """ì¶œë ¥ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ê³µê°œ URLì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if rp_upload is None:
        raise RuntimeError("rp_upload ëª¨ë“ˆì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëŸ°í¬ë“œ ì„œë²„ë¦¬ìŠ¤ í™˜ê²½ì—ì„œ ì‹¤í–‰í•´ ì£¼ì„¸ìš”.")

    uploaded_files: Dict[str, str] = {}
    for output_file in file_paths:
        if os.path.exists(output_file):
            try:
                upload_result = rp_upload.upload_file(output_file)
                # upload_result ì˜ˆ: { 'file_id': str, 'url'|'link': str }
                url_value = upload_result.get('url') or upload_result.get('link')
                uploaded_files[os.path.basename(output_file)] = url_value
                logger.info(f"ì—…ë¡œë“œ ì™„ë£Œ: {output_file} -> {url_value}")
            except Exception as e:
                logger.error(f"íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {output_file} - {e}")
                raise
        else:
            logger.warning(f"íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {output_file}")
    return uploaded_files

# ì „ì—­ ë³€ìˆ˜ë¡œ AICoverGenHandler ì¸ìŠ¤í„´ìŠ¤ ì €ì¥ (Cold start ìµœì í™”)
aicovergen_handler = None

def discover_voice_models(models_root: str) -> list:
    """Discover valid voice model directories that contain at least one .pth file.
    Hidden items and non-directories are ignored.
    """
    if not os.path.isdir(models_root):
        return []
    discovered = []
    try:
        for name in os.listdir(models_root):
            if name.startswith('.'):
                continue
            full_path = os.path.join(models_root, name)
            if not os.path.isdir(full_path):
                continue
            try:
                if any(fname.endswith('.pth') for fname in os.listdir(full_path)):
                    discovered.append(name)
            except Exception:
                continue
    except Exception as e:
        logger.warning(f"ëª¨ë¸ ë””ë ‰í„°ë¦¬ ìŠ¤ìº” ì¤‘ ê²½ê³ : {e}")
    return discovered


def load_aicovergen_handler():
    """AICoverGenHandler ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë¡œë“œí•˜ê³  ëª¨ë¸ì„ ì¤€ë¹„í•©ë‹ˆë‹¤."""
    global aicovergen_handler
    if aicovergen_handler is None:
        try:
            logger.info("AICoverGenHandler ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì´ˆê¸°í™”í•˜ê³  ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤...")
            aicovergen_handler = AICoverGenHandler()
            logger.info("AICoverGenHandler ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.error(f"AICoverGenHandler ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            raise
    return aicovergen_handler

class AICoverGenHandler:
    def __init__(self):
        """Initialize the AICoverGen handler"""
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        logger.info(f"Using device: {self.device}")
        
        # Load available models from RunPod volume (filtered)
        self.voice_models = discover_voice_models(RUNPOD_RVC_MODELS_DIR)
        logger.info(f"Available voice models: {self.voice_models}")
        
        # Set torch to use memory efficiently for serverless
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.backends.cudnn.benchmark = True
    
    def health_check(self) -> Dict[str, Any]:
        """Health check endpoint"""
        return {
            "status": "healthy",
            "device": self.device,
            "available_models": self.voice_models,
            "gpu_available": torch.cuda.is_available(),
            "s3_available": S3_AVAILABLE,
            "s3_bucket": S3_BUCKET_NAME if S3_AVAILABLE else None,
            "aws_env_debug": {
                "AWS_ACCESS_KEY_ID": "ì„¤ì •ë¨" if AWS_ACCESS_KEY_ID else "ì—†ìŒ",
                "AWS_SECRET_ACCESS_KEY": "ì„¤ì •ë¨" if AWS_SECRET_ACCESS_KEY else "ì—†ìŒ", 
                "AWS_REGION": AWS_REGION,
                "S3_BUCKET_NAME": S3_BUCKET_NAME
            },
            "supported_input_types": ["voice_audio_url", "instrument_audio_url"] if S3_AVAILABLE else ["voice_audio", "instrument_audio"],
            "supported_return_types": ["url", "base64"] if S3_AVAILABLE else ["base64"],
            "code_version": "backup_vocals_removed_v2.1",  # ì½”ë“œ ë³€ê²½ í™•ì¸ìš© ë§ˆì»¤
            "backup_vocals_removed": True,  # ë°±ì—… ë³´ì»¬ ì œê±° í™•ì¸
            "combine_audio_signature": "main_gain_inst_gain_only"  # í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ í™•ì¸
        }
    
    def list_models(self) -> Dict[str, Any]:
        """List available voice models"""
        return {
            "models": self.voice_models,
            "count": len(self.voice_models)
        }
    
    def check_model_files(self) -> Dict[str, Any]:
        """Check the status of model files"""
        try:
            model_status = {}
            
            # Check RVC base models
            rvc_base_models = ["hubert_base.pt", "rmvpe.pt"]
            for model in rvc_base_models:
                model_path = os.path.join(RUNPOD_RVC_MODELS_DIR, model)
                if os.path.exists(model_path):
                    file_size = os.path.getsize(model_path) / (1024 * 1024)  # MB
                    model_status[model] = {
                        "exists": True,
                        "size_mb": round(file_size, 2),
                        "path": model_path
                    }
                else:
                    model_status[model] = {
                        "exists": False,
                        "size_mb": 0,
                        "path": model_path
                    }
            
            # Check voice models
            voice_model_status = {}
            for voice_model in self.voice_models:
                model_dir = os.path.join(RUNPOD_RVC_MODELS_DIR, voice_model)
                if os.path.exists(model_dir):
                    files = os.listdir(model_dir)
                    voice_model_status[voice_model] = {
                        "exists": True,
                        "files": files,
                        "path": model_dir
                    }
                else:
                    voice_model_status[voice_model] = {
                        "exists": False,
                        "files": [],
                        "path": model_dir
                    }
            
            return {
                "rvc_base_models": model_status,
                "voice_models": voice_model_status,
                "runpod_volume_exists": os.path.exists("/runpod-volume"),
                "runpod_rvc_models_dir": RUNPOD_RVC_MODELS_DIR
            }
        except Exception as e:
            logger.error(f"ëª¨ë¸ íŒŒì¼ ìƒíƒœ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {
                "error": str(e),
                "traceback": traceback.format_exc()
            }
    
    def get_rvc_model(self, voice_model: str) -> tuple:
        """Get RVC model paths"""
        rvc_model_filename, rvc_index_filename = None, None
        model_dir = os.path.join(RUNPOD_RVC_MODELS_DIR, voice_model)
        
        for file in os.listdir(model_dir):
            ext = os.path.splitext(file)[1]
            if ext == '.pth':
                rvc_model_filename = file
            if ext == '.index':
                rvc_index_filename = file

        if rvc_model_filename is None:
            raise Exception(f'No model file exists in {model_dir}.')

        return os.path.join(model_dir, rvc_model_filename), os.path.join(model_dir, rvc_index_filename) if rvc_index_filename else ''
    
    def voice_change(self, voice_model: str, vocals_path: str, output_path: str, 
                    pitch_change: int, f0_method: str, index_rate: float, 
                    filter_radius: int, rms_mix_rate: float, protect: float, 
                    crepe_hop_length: int):
        """Convert voice using RVC - using main.py logic"""
        # Override all module paths to point to RunPod volume
        main_module.rvc_models_dir = RUNPOD_RVC_MODELS_DIR
        main_module.mdxnet_models_dir = RUNPOD_MDXNET_MODELS_DIR
        main_module.output_dir = RUNPOD_OUTPUT_DIR
        
        # Also override webui module paths
        import webui
        webui.rvc_models_dir = RUNPOD_RVC_MODELS_DIR
        webui.mdxnet_models_dir = RUNPOD_MDXNET_MODELS_DIR
        webui.output_dir = RUNPOD_OUTPUT_DIR
        
        # Set environment variables for other modules that use BASE_DIR
        os.environ['RVC_MODELS_DIR'] = RUNPOD_RVC_MODELS_DIR
        os.environ['MDXNET_MODELS_DIR'] = RUNPOD_MDXNET_MODELS_DIR
        os.environ['OUTPUT_DIR'] = RUNPOD_OUTPUT_DIR
        
        # Override BASE_DIR for modules that use it
        import sys
        if 'src' in sys.modules:
            src_module = sys.modules['src']
            if hasattr(src_module, 'BASE_DIR'):
                src_module.BASE_DIR = RUNPOD_RVC_MODELS_DIR
        
        # Call main.py's voice_change
        main_module.voice_change(voice_model, vocals_path, output_path, pitch_change, 
                                 f0_method, index_rate, filter_radius, rms_mix_rate, 
                                 protect, crepe_hop_length, is_webui=False)
    
    def add_audio_effects(self, audio_path: str, reverb_rm_size: float, 
                         reverb_wet: float, reverb_dry: float, reverb_damping: float) -> str:
        """Apply audio effects to vocals - using main.py logic"""
        output_path = f'{os.path.splitext(audio_path)[0]}_mixed.wav'

        # Initialize audio effects plugins - same as main.py
        board = Pedalboard(
            [
                HighpassFilter(),
                Compressor(ratio=4, threshold_db=-15),
                Reverb(room_size=reverb_rm_size, dry_level=reverb_dry, wet_level=reverb_wet, damping=reverb_damping)
             ]
        )

        with AudioFile(audio_path) as f:
            with AudioFile(output_path, 'w', f.samplerate, f.num_channels) as o:
                # Read one second of audio at a time, until the file is empty:
                while f.tell() < f.frames:
                    chunk = f.read(int(f.samplerate))
                    effected = board(chunk, f.samplerate, reset=False)
                    o.write(effected)

        return output_path
    
    def combine_audio(self, audio_paths: list, output_path: str, main_gain: int, 
                     inst_gain: int, output_format: str):
        """Combine AI vocals and instrumentals - using main.py logic"""
        # ë””ë²„ê¹… ì •ë³´ ì¶œë ¥
        logger.info(f"ğŸµ ì˜¤ë””ì˜¤ íŒŒì¼ ê²°í•© ì¤‘:")
        logger.info(f"   ë³´ì»¬ íŒŒì¼: {audio_paths[0]}")
        logger.info(f"   ì•…ê¸° íŒŒì¼: {audio_paths[1]}")
        logger.info(f"   ì¶œë ¥ ê²½ë¡œ: {output_path}")
        logger.info(f"   main_gain: {main_gain}, inst_gain: {inst_gain}")
        
        try:
            # íŒŒì¼ í˜•ì‹ ìë™ ê°ì§€ (WAV/MP3 ëª¨ë‘ ì§€ì›)
            main_vocal_audio = AudioSegment.from_file(audio_paths[0]) - 4 + main_gain
            instrumental_audio = AudioSegment.from_file(audio_paths[1]) - 7 + inst_gain
            main_vocal_audio.overlay(instrumental_audio).export(output_path, format=output_format)
            logger.info(f"âœ… ì˜¤ë””ì˜¤ ê²°í•© ì™„ë£Œ: {output_path}")
        except Exception as e:
            logger.error(f"âŒ ì˜¤ë””ì˜¤ ê²°í•© ì‹¤íŒ¨: {str(e)}")
            # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            for i, path in enumerate(audio_paths):
                exists = os.path.exists(path) if path.startswith('/') else True  # S3 URLì¸ ê²½ìš° ì¡´ì¬í•œë‹¤ê³  ê°€ì •
                logger.error(f"   íŒŒì¼ {i}: {path} - ì¡´ì¬: {exists}")
            raise
    
    def pitch_shift(self, audio_path: str, pitch_change: int) -> str:
        """Apply pitch shift to audio - using main.py logic"""
        return main_module.pitch_shift(audio_path, pitch_change)
    
    def generate_cover_from_separate_audio(self, 
                                         voice_audio: Optional[str] = None,  # base64 encoded voice audio (deprecated)
                                         instrument_audio: Optional[str] = None,  # base64 encoded instrument audio (deprecated)
                                         voice_audio_url: Optional[str] = None,  # S3 URL for voice audio (preferred)
                                         instrument_audio_url: Optional[str] = None,  # S3 URL for instrument audio (preferred)
                                         voice_model: str = '',
                                         pitch_adjust: int = 0,
                                         index_rate: float = 0.75,
                                         filter_radius: int = 3,
                                         rms_mix_rate: float = 0.25,
                                         protect: float = 0.33,
                                         f0_method: str = "rmvpe",
                                         crepe_hop_length: int = 128,
                                         pitch_change_all: int = 0,
                                         reverb_rm_size: float = 0.15,
                                         reverb_wet: float = 0.2,
                                         reverb_dry: float = 0.8,
                                         reverb_damping: float = 0.7,
                                         main_gain: int = 0,

                                         inst_gain: int = 0,
                                         output_format: str = "mp3",
                                         return_type: str = "url",  # 'url' | 'base64', default to 'url'
                                         **kwargs) -> Dict[str, Any]:
        """
        Generate AI cover from separate voice and instrument audio files
        
        Args:
            voice_audio: Base64 encoded voice audio file (deprecated, use voice_audio_url)
            instrument_audio: Base64 encoded instrument audio file (deprecated, use instrument_audio_url)
            voice_audio_url: S3 URL for voice audio (preferred method)
            instrument_audio_url: S3 URL for instrument audio (preferred method)
            voice_model: Name of the voice model to use
            pitch_adjust: Pitch adjustment for voice conversion
            index_rate: Index rate for voice conversion
            filter_radius: Filter radius
            rms_mix_rate: RMS mix rate
            protect: Protection value
            f0_method: F0 method
            crepe_hop_length: Crepe hop length
            pitch_change_all: Overall pitch change for all audio
            reverb_rm_size: Reverb room size
            reverb_wet: Reverb wet level
            reverb_dry: Reverb dry level
            reverb_damping: Reverb damping
            main_gain: Volume change for AI main vocals

            inst_gain: Volume change for instrumentals
            output_format: Output format of audio file
            return_type: 'url' for S3 URL output, 'base64' for base64 output
            
        Returns:
            Dict containing the generated audio file (URL or base64) and metadata
        """
        try:
            # Validate voice model
            if voice_model not in self.voice_models:
                return {
                    "error": f"Voice model '{voice_model}' not found. Available models: {self.voice_models}"
                }
            
            # Create temporary directory for processing
            with tempfile.TemporaryDirectory() as temp_dir:
                # Prepare file paths (will be downloaded from S3 or decoded from base64)
                voice_path = None
                instrument_path = None

                # Temporary files to clean up later
                temp_files_to_cleanup = []

                # Handle voice audio input - prefer S3 URL
                if voice_audio_url:
                    if not S3_AVAILABLE:
                        return {"error": "S3 URLì´ ì œê³µë˜ì—ˆì§€ë§Œ S3 ìê²©ì¦ëª…ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. AWS í™˜ê²½ë³€ìˆ˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."}
                    logger.info("[~] Downloading voice audio from S3...")
                    voice_path = _download_from_s3(voice_audio_url)
                    temp_files_to_cleanup.append(voice_path)
                elif voice_audio:
                    logger.info("[~] Decoding voice audio from base64...")
                    try:
                        voice_data = base64.b64decode(voice_audio)
                        voice_path = os.path.join(temp_dir, "voice_input.wav")
                        with open(voice_path, 'wb') as f:
                            f.write(voice_data)
                    except Exception as e:
                        return {"error": f"Invalid base64 voice audio data: {str(e)}"}
                else:
                    return {"error": "Missing voice audio. Provide 'voice_audio_url' (S3 URL) or 'voice_audio' (base64)."}

                # Handle instrument audio input - prefer S3 URL
                if instrument_audio_url:
                    if not S3_AVAILABLE:
                        return {"error": "S3 URLì´ ì œê³µë˜ì—ˆì§€ë§Œ S3 ìê²©ì¦ëª…ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. AWS í™˜ê²½ë³€ìˆ˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."}
                    logger.info("[~] Downloading instrument audio from S3...")
                    instrument_path = _download_from_s3(instrument_audio_url)
                    temp_files_to_cleanup.append(instrument_path)
                elif instrument_audio:
                    logger.info("[~] Decoding instrument audio from base64...")
                    try:
                        instrument_data = base64.b64decode(instrument_audio)
                        instrument_path = os.path.join(temp_dir, "instrument_input.wav")
                        with open(instrument_path, 'wb') as f:
                            f.write(instrument_data)
                    except Exception as e:
                        return {"error": f"Invalid base64 instrument audio data: {str(e)}"}
                else:
                    return {"error": "Missing instrument audio. Provide 'instrument_audio_url' (S3 URL) or 'instrument_audio' (base64)."}
                
                # Generate unique song ID from file contents
                hasher = hashlib.blake2b(digest_size=6)
                for p in [voice_path, instrument_path]:
                    with open(p, 'rb') as fh:
                        for chunk in iter(lambda: fh.read(8192), b''):
                            hasher.update(chunk)
                song_id = hasher.hexdigest()
                song_dir = os.path.join(temp_dir, song_id)
                os.makedirs(song_dir, exist_ok=True)
                
                # Voice conversion (main.py 289-292 lines equivalent)
                pitch_change = pitch_adjust * 12 + pitch_change_all
                ai_vocals_path = os.path.join(song_dir, f'voice_{voice_model}_p{pitch_change}_i{index_rate}_fr{filter_radius}_rms{rms_mix_rate}_pro{protect}_{f0_method}{"" if f0_method != "mangio-crepe" else f"_{crepe_hop_length}"}.wav')
                
                logger.info('[~] Converting voice using RVC...')
                self.voice_change(voice_model, voice_path, ai_vocals_path, pitch_change, 
                                  f0_method, index_rate, filter_radius, rms_mix_rate, 
                                  protect, crepe_hop_length)
                
                # Apply audio effects to vocals (main.py 294-295 lines equivalent)
                logger.info('[~] Applying audio effects to Vocals...')
                ai_vocals_mixed_path = self.add_audio_effects(ai_vocals_path, reverb_rm_size, 
                                                              reverb_wet, reverb_dry, reverb_damping)
                
                # Apply overall pitch change if needed (main.py 297-300 lines equivalent)
                if pitch_change_all != 0:
                    logger.info('[~] Applying overall pitch change')
                    instrument_path = self.pitch_shift(instrument_path, pitch_change_all)
                
                # Combine AI vocals and instrumentals (main.py 302-303 lines equivalent)
                logger.info('[~] Combining AI Vocals and Instrumentals...')
                ai_cover_path_wav = os.path.join(song_dir, f'cover_{voice_model}.wav')
                self.combine_audio([ai_vocals_mixed_path, instrument_path], 
                                   ai_cover_path_wav, main_gain, inst_gain, 'wav')
                
                # Convert to MP3 if requested
                if (output_format or '').lower() == 'mp3':
                    logger.info('[~] Converting WAV to MP3...')
                    final_output_path = os.path.join(song_dir, f'cover_{voice_model}.mp3')
                    audio_seg = AudioSegment.from_file(ai_cover_path_wav)
                    audio_seg.export(final_output_path, format='mp3')
                else:
                    final_output_path = ai_cover_path_wav
                
                # Prepare result based on return_type
                result = {
                    "success": True,
                    "filename": os.path.basename(final_output_path),
                    "size": os.path.getsize(final_output_path),
                    "model_used": voice_model,
                    "return_type": return_type,
                    "parameters": {
                        "pitch_adjust": pitch_adjust,
                        "index_rate": index_rate,
                        "filter_radius": filter_radius,
                        "rms_mix_rate": rms_mix_rate,
                        "protect": protect,
                        "f0_method": f0_method,
                        "pitch_change_all": pitch_change_all,
                        "reverb_rm_size": reverb_rm_size,
                        "reverb_wet": reverb_wet,
                        "reverb_dry": reverb_dry,
                        "reverb_damping": reverb_damping,
                        "main_gain": main_gain,

                        "inst_gain": inst_gain,
                        "output_format": (output_format or 'wav')
                    }
                }

                # Handle output based on return_type
                try:
                    if return_type == "url":
                        # Upload to S3 and return URL
                        if not S3_AVAILABLE:
                            logger.warning("S3ê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•˜ë¯€ë¡œ base64ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
                            # Fallback to base64
                            with open(final_output_path, 'rb') as f:
                                audio_bytes = f.read()
                                audio_b64 = base64.b64encode(audio_bytes).decode('utf-8')
                            result["output_audio"] = audio_b64
                            result["return_type"] = "base64"
                            logger.info("[+] Base64 encoding completed (S3 fallback)")
                        else:
                            logger.info("[~] Uploading result to S3...")
                            output_url = _upload_to_s3(final_output_path, "audio")
                            result["output_url"] = output_url
                            logger.info(f"[+] S3 upload completed: {output_url}")
                    else:
                        # Return as base64 (fallback)
                        logger.info("[~] Encoding result as base64...")
                        with open(final_output_path, 'rb') as f:
                            audio_bytes = f.read()
                            audio_b64 = base64.b64encode(audio_bytes).decode('utf-8')
                        result["output_audio"] = audio_b64
                        logger.info("[+] Base64 encoding completed")
                        
                finally:
                    # Clean up temporary S3 downloaded files
                    for temp_file in temp_files_to_cleanup:
                        try:
                            if os.path.exists(temp_file):
                                os.unlink(temp_file)
                                logger.info(f"Cleaned up temp file: {temp_file}")
                        except Exception as e:
                            logger.warning(f"Failed to cleanup temp file {temp_file}: {e}")
                
                # Clean up GPU memory after successful generation
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                    gc.collect()
                
                return result
                        
        except Exception as e:
            logger.error(f"Error during cover generation: {str(e)}")
            logger.error(traceback.format_exc())
            
            # Clean up temporary S3 downloaded files in case of error
            if 'temp_files_to_cleanup' in locals():
                for temp_file in temp_files_to_cleanup:
                    try:
                        if os.path.exists(temp_file):
                            os.unlink(temp_file)
                            logger.info(f"Cleaned up temp file on error: {temp_file}")
                    except Exception as cleanup_error:
                        logger.warning(f"Failed to cleanup temp file on error {temp_file}: {cleanup_error}")
            
            # Clean up GPU memory
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                gc.collect()
            
            return {
                "error": f"Error during cover generation: {str(e)}",
                "traceback": traceback.format_exc()
            }

def handler(job):
    """
    RunPod Serverless í•¸ë“¤ëŸ¬ í•¨ìˆ˜
    
    Args:
        job: RunPodì—ì„œ ì „ë‹¬í•˜ëŠ” ì‘ì—… ë°ì´í„°
        
    Returns:
        Dict: ì²˜ë¦¬ ê²°ê³¼
    """
    try:
        job_input = job.get("input", {})
        logger.info(f"ì‘ì—… ì…ë ¥: {job_input}")
        
        # ì‘ì—… íƒ€ì… í™•ì¸
        operation = job_input.get("operation", "generate_cover_from_separate_audio")
        
        logger.info(f"Processing operation: {operation}")
        
        # AICoverGenHandler ì¸ìŠ¤í„´ìŠ¤ ë¡œë“œ
        handler_instance = load_aicovergen_handler()
        
        # Route to appropriate handler method
        if operation == "health_check":
            return handler_instance.health_check()
        elif operation == "list_models":
            return handler_instance.list_models()
        elif operation == "check_model_files":
            return handler_instance.check_model_files()
        elif operation == "generate_cover_from_separate_audio":
            # Extract parameters for cover generation from separate audio files
            params = job_input.get("params", {})
            # Default to 'url' for S3-based operation, but allow override
            if "return_type" not in params:
                params["return_type"] = "url"
            
            result = handler_instance.generate_cover_from_separate_audio(**params)
            return result
        else:
            return {
                "error": f"Unknown operation: {operation}. Available operations: health_check, list_models, generate_cover_from_separate_audio"
            }
            
    except Exception as e:
        logger.error(f"í•¸ë“¤ëŸ¬ ì˜¤ë¥˜: {str(e)}")
        logger.error(traceback.format_exc())
        return {
            "error": "Internal server error",
            "message": str(e)
        }

# Cold start ìµœì í™”: ì»¨í…Œì´ë„ˆ ì‹œì‘ ì‹œ ëª¨ë¸ ë¯¸ë¦¬ ë¡œë“œ
try:
    logger.info("ì»¨í…Œì´ë„ˆ ì‹œì‘ ì‹œ ëª¨ë¸ ë¯¸ë¦¬ ë¡œë“œ ì¤‘...")
    load_aicovergen_handler()
    logger.info("Cold start ìµœì í™” ì™„ë£Œ")
except Exception as e:
    logger.error(f"Cold start ìµœì í™” ì‹¤íŒ¨: {str(e)}")

# ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš© í•¨ìˆ˜
def test_local():
    """ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš© í•¨ìˆ˜"""
    print("=== ë¡œì»¬ í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
    
    # í—¬ìŠ¤ì²´í¬ í…ŒìŠ¤íŠ¸
    print("1. í—¬ìŠ¤ì²´í¬ í…ŒìŠ¤íŠ¸")
    try:
        handler_instance = load_aicovergen_handler()
        result = handler_instance.health_check()
        print(f"ê²°ê³¼: {result}")
    except Exception as e:
        print(f"ì˜¤ë¥˜: {e}")
    
    # ëª¨ë¸ ëª©ë¡ ì¡°íšŒ í…ŒìŠ¤íŠ¸
    print("2. ëª¨ë¸ ëª©ë¡ ì¡°íšŒ í…ŒìŠ¤íŠ¸")
    try:
        result = handler_instance.list_models()
        print(f"ê²°ê³¼: {result}")
    except Exception as e:
        print(f"ì˜¤ë¥˜: {e}")
    
    print("\n=== ë¡œì»¬ í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===")

# RunPod Serverless ì‹œì‘
if __name__ == "__main__":
    # ë¡œì»¬ í…ŒìŠ¤íŠ¸ ëª¨ë“œ í™•ì¸
    if os.getenv("LOCAL_TEST", "false").lower() == "true":
        test_local()
    else:
        runpod.serverless.start({"handler": handler})
